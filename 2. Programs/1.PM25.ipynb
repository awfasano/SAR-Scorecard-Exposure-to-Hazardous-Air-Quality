{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5222c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ Already exists: afg_ppp_2010_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2010_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2010_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2010_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2010_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2010_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2010_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2010_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: afg_ppp_2011_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2011_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2011_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2011_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2011_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2011_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2011_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2011_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: afg_ppp_2012_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2012_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2012_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2012_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2012_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2012_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2012_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2012_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: afg_ppp_2013_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2013_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2013_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2013_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2013_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2013_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2013_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2013_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: afg_ppp_2014_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2014_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2014_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2014_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2014_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2014_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2014_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2014_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: afg_ppp_2015_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2015_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2015_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2015_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2015_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2015_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2015_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2015_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: afg_ppp_2016_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2016_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2016_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2016_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2016_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2016_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2016_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2016_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: afg_ppp_2017_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2017_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2017_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2017_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2017_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2017_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2017_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2017_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: afg_ppp_2018_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2018_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2018_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2018_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2018_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2018_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2018_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2018_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: afg_ppp_2019_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2019_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2019_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2019_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2019_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2019_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2019_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2019_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: afg_ppp_2020_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2020_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2020_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2020_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2020_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2020_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2020_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2020_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: afg_ppp_2021_1km_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2021_1km_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2021_1km_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2021_1km_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2021_1km_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2021_1km_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2021_1km_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2021_1km_UNadj.tif\n",
      "✔️ Already exists: afg_ppp_2022_1km_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2022_1km_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2022_1km_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2022_1km_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2022_1km_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2022_1km_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2022_1km_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2022_1km_UNadj.tif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Output directory\n",
    "output_dir = r\"C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# South Asia ISO3 codes\n",
    "south_asia_iso3 = {\n",
    "    'AFG': 'Afghanistan',\n",
    "    'BGD': 'Bangladesh',\n",
    "    'BTN': 'Bhutan',\n",
    "    'IND': 'India',\n",
    "    'MDV': 'Maldives',\n",
    "    'NPL': 'Nepal',\n",
    "    'PAK': 'Pakistan',\n",
    "    'LKA': 'Sri_Lanka'\n",
    "}\n",
    "\n",
    "# URL base by year and structure\n",
    "def build_url(year, iso3):\n",
    "    iso3_lower = iso3.lower()\n",
    "    \n",
    "    if year <= 2020:\n",
    "        base_url = f\"https://data.worldpop.org/GIS/Population/Global_2000_2020_1km_UNadj/{year}/{iso3}/\"\n",
    "        filename = f\"{iso3_lower}_ppp_{year}_1km_Aggregated_UNadj.tif\"\n",
    "    else:\n",
    "        base_url = f\"https://data.worldpop.org/GIS/Population/Global_2021_2022_1km_UNadj/unconstrained/{year}/{iso3}/\"\n",
    "        filename = f\"{iso3_lower}_ppp_{year}_1km_UNadj.tif\"\n",
    "    \n",
    "    return base_url + filename, filename\n",
    "\n",
    "# Download loop\n",
    "for year in range(2010, 2023):\n",
    "    for iso3 in south_asia_iso3:\n",
    "        url, filename = build_url(year, iso3)\n",
    "        save_path = os.path.join(output_dir, f\"{iso3}_{year}.tif\")\n",
    "\n",
    "        if os.path.exists(save_path):\n",
    "            print(f\"✔️ Already exists: {filename}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"⬇️ Downloading {filename} from {url}...\")\n",
    "        r = requests.get(url, stream=True)\n",
    "        if r.status_code == 200:\n",
    "            with open(save_path, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "            print(f\"✅ Saved to: {save_path}\")\n",
    "        else:\n",
    "            print(f\"❌ Failed to download {filename} (Status code: {r.status_code})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8305a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Data for  PM25 cannot be downaloaed with script ; it is hosted in BOX \n",
    "#  https://sites.wustl.edu/acag/datasets/surface-pm2-5/#V5.GL.05.02\n",
    "#  https://wustl.app.box.com/v/ACAG-V5GL0502-GWRPM25/folder/293382100161\n",
    "#  Manual Download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d705b28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables in file: ['lon', 'lat', 'GWRPM25']\n"
     ]
    }
   ],
   "source": [
    "from netCDF4 import Dataset\n",
    "\n",
    "# Path to your NetCDF file\n",
    "nc_path = r\"C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\V5GL0502.HybridPM25.Asia.201001-201012.nc\"\n",
    "\n",
    "# Open file\n",
    "ds = Dataset(nc_path, mode='r')\n",
    "\n",
    "# List all variables\n",
    "print(\"Variables in file:\", list(ds.variables.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "554d1f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Processing year 2010...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2010.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2010.tif\n",
      "\n",
      "🔄 Processing year 2011...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2011.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2011.tif\n",
      "\n",
      "🔄 Processing year 2012...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2012.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2012.tif\n",
      "\n",
      "🔄 Processing year 2013...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2013.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2013.tif\n",
      "\n",
      "🔄 Processing year 2014...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2014.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2014.tif\n",
      "\n",
      "🔄 Processing year 2015...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2015.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2015.tif\n",
      "\n",
      "🔄 Processing year 2016...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2016.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2016.tif\n",
      "\n",
      "🔄 Processing year 2017...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2017.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2017.tif\n",
      "\n",
      "🔄 Processing year 2018...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2018.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2018.tif\n",
      "\n",
      "🔄 Processing year 2019...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2019.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2019.tif\n",
      "\n",
      "🔄 Processing year 2020...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2020.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2020.tif\n",
      "\n",
      "🔄 Processing year 2021...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2021.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2021.tif\n",
      "\n",
      "🔄 Processing year 2022...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2022.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2022.tif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from netCDF4 import Dataset\n",
    "from rasterio.transform import from_bounds\n",
    "from rasterio.merge import merge\n",
    "from rasterio.crs import CRS\n",
    "\n",
    "# Years to process\n",
    "years = [str(y) for y in range(2010, 2023)]\n",
    "\n",
    "# PM2.5 paths\n",
    "pm25_nc_dir = r\"C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\"\n",
    "pm25_tif_dir = os.path.join(pm25_nc_dir, \"tifs\")\n",
    "os.makedirs(pm25_tif_dir, exist_ok=True)\n",
    "\n",
    "# Population paths\n",
    "pop_dir = r\"C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\"\n",
    "pop_tif_dir = os.path.join(pop_dir, \"tifs\")\n",
    "os.makedirs(pop_tif_dir, exist_ok=True)\n",
    "\n",
    "# ISO3 list for South Asia\n",
    "iso3_list = ['AFG', 'BGD', 'BTN', 'IND', 'MDV', 'NPL', 'PAK', 'LKA']\n",
    "\n",
    "# Loop over years\n",
    "for year in years:\n",
    "    print(f\"\\n🔄 Processing year {year}...\")\n",
    "\n",
    "    # === PM2.5 NetCDF to TIFF ===\n",
    "    nc_file = os.path.join(pm25_nc_dir, f\"V5GL0502.HybridPM25.Global.{year}01-{year}12.nc\")\n",
    "    ds = Dataset(nc_file)\n",
    "    pm25_data = ds.variables['GWRPM25'][:, :]\n",
    "    lats = ds.variables['lat'][:]\n",
    "    lons = ds.variables['lon'][:]\n",
    "    ds.close()\n",
    "\n",
    "    # ✅ Flip data if lat is descending; DO NOT flip lats\n",
    "    if lats[0] > lats[-1]:\n",
    "        pm25_data = pm25_data[::-1, :]  # Flip data only\n",
    "\n",
    "    # ✅ Use lats.max() as top and lats.min() as bottom\n",
    "    height, width = pm25_data.shape\n",
    "    transform = from_bounds(lons.min(), lats.max(), lons.max(), lats.min(), width, height)\n",
    "\n",
    "    pm25_output_path = os.path.join(pm25_tif_dir, f\"pm25_{year}.tif\")\n",
    "    with rasterio.open(\n",
    "        pm25_output_path,\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=height,\n",
    "        width=width,\n",
    "        count=1,\n",
    "        dtype=pm25_data.dtype,\n",
    "        crs=CRS.from_epsg(4326),\n",
    "        transform=transform,\n",
    "        nodata=-999\n",
    "    ) as dst:\n",
    "        dst.write(pm25_data, 1)\n",
    "\n",
    "    print(f\"✅ PM2.5 saved to: {pm25_output_path}\")\n",
    "\n",
    "    \n",
    "    # === Population Mosaic to TIFF ===\n",
    "    \n",
    "    src_files = []\n",
    "    for iso3 in iso3_list:\n",
    "        pop_file = os.path.join(pop_dir, f\"{iso3}_{year}.tif\")\n",
    "        if os.path.exists(pop_file):\n",
    "            src = rasterio.open(pop_file)\n",
    "            src_files.append(src)\n",
    "        else:\n",
    "            print(f\"⚠️ Missing: {pop_file}\")\n",
    "\n",
    "    if src_files:\n",
    "        mosaic, out_transform = merge(src_files, nodata=0)\n",
    "        out_meta = src_files[0].meta.copy()\n",
    "        out_meta.update({\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"height\": mosaic.shape[1],\n",
    "            \"width\": mosaic.shape[2],\n",
    "            \"transform\": out_transform,\n",
    "            \"nodata\": 0,\n",
    "            \"crs\": CRS.from_epsg(4326)\n",
    "        })\n",
    "\n",
    "        pop_output_path = os.path.join(pop_tif_dir, f\"pop_south_asia_{year}.tif\")\n",
    "        with rasterio.open(pop_output_path, \"w\", **out_meta) as dest:\n",
    "            dest.write(mosaic)\n",
    "\n",
    "        print(f\"✅ Population mosaic saved to: {pop_output_path}\")\n",
    "\n",
    "        for src in src_files:\n",
    "            src.close()\n",
    "    else:\n",
    "        print(f\"❌ No population data found for {year}\")    \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a523d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Processing year 2010...\n",
      "✅ Full dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_full_2010.csv\n",
      "✅ Aggregated dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_aggregated_2010.csv\n",
      "\n",
      "🔄 Processing year 2011...\n",
      "✅ Full dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_full_2011.csv\n",
      "✅ Aggregated dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_aggregated_2011.csv\n",
      "\n",
      "🔄 Processing year 2012...\n",
      "✅ Full dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_full_2012.csv\n",
      "✅ Aggregated dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_aggregated_2012.csv\n",
      "\n",
      "🔄 Processing year 2013...\n",
      "✅ Full dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_full_2013.csv\n",
      "✅ Aggregated dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_aggregated_2013.csv\n",
      "\n",
      "🔄 Processing year 2014...\n",
      "✅ Full dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_full_2014.csv\n",
      "✅ Aggregated dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_aggregated_2014.csv\n",
      "\n",
      "🔄 Processing year 2015...\n",
      "✅ Full dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_full_2015.csv\n",
      "✅ Aggregated dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_aggregated_2015.csv\n",
      "\n",
      "🔄 Processing year 2016...\n",
      "✅ Full dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_full_2016.csv\n",
      "✅ Aggregated dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_aggregated_2016.csv\n",
      "\n",
      "🔄 Processing year 2017...\n",
      "✅ Full dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_full_2017.csv\n",
      "✅ Aggregated dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_aggregated_2017.csv\n",
      "\n",
      "🔄 Processing year 2018...\n",
      "✅ Full dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_full_2018.csv\n",
      "✅ Aggregated dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_aggregated_2018.csv\n",
      "\n",
      "🔄 Processing year 2019...\n",
      "✅ Full dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_full_2019.csv\n",
      "✅ Aggregated dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_aggregated_2019.csv\n",
      "\n",
      "🔄 Processing year 2020...\n",
      "✅ Full dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_full_2020.csv\n",
      "✅ Aggregated dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_aggregated_2020.csv\n",
      "\n",
      "🔄 Processing year 2021...\n",
      "✅ Full dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_full_2021.csv\n",
      "✅ Aggregated dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_aggregated_2021.csv\n",
      "\n",
      "🔄 Processing year 2022...\n",
      "✅ Full dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_full_2022.csv\n",
      "✅ Aggregated dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin2_aggregated_2022.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.warp import reproject, Resampling\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Paths\n",
    "pop_dir = r\"C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\"\n",
    "pm25_dir = r\"C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\"\n",
    "shapefile_path = r\"C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Shapefile\\WB_GAD\\WB_GAD_ADM2_SAR_Clean.shp\"\n",
    "output_dir = r\"C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load ADM2 shapefile\n",
    "adm2 = gpd.read_file(shapefile_path).to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Years to process\n",
    "years = [str(y) for y in range(2010, 2023)]\n",
    "\n",
    "for year in years:\n",
    "    print(f\"\\n🔄 Processing year {year}...\")\n",
    "\n",
    "    # Load population\n",
    "    pop_path = os.path.join(pop_dir, f\"pop_south_asia_{year}.tif\")\n",
    "    with rasterio.open(pop_path) as pop_src:\n",
    "        pop_data = pop_src.read(1, masked=True)\n",
    "        pop_meta = pop_src.meta.copy()\n",
    "        pop_transform = pop_src.transform\n",
    "        pop_crs = pop_src.crs\n",
    "        bounds = pop_src.bounds\n",
    "        height, width = pop_data.shape\n",
    "\n",
    "    # Load PM2.5 and reproject to match population\n",
    "    pm_path = os.path.join(pm25_dir, f\"pm25_{year}.tif\")\n",
    "    with rasterio.open(pm_path) as pm_src:\n",
    "        pm_data_orig = pm_src.read(1, masked=True)\n",
    "        pm_resampled = np.empty_like(pop_data, dtype=np.float32)\n",
    "\n",
    "        reproject(\n",
    "            source=pm_data_orig,\n",
    "            destination=pm_resampled,\n",
    "            src_transform=pm_src.transform,\n",
    "            src_crs=pm_src.crs,\n",
    "            dst_transform=pop_transform,\n",
    "            dst_crs=pop_crs,\n",
    "            resampling=Resampling.bilinear\n",
    "        )\n",
    "\n",
    "    # Mask valid population cells\n",
    "    valid_mask = (pop_data > 0) & (~np.isnan(pm_resampled))\n",
    "    exposed_mask = valid_mask & (pm_resampled > 5)\n",
    "\n",
    "    # Create coordinates\n",
    "    res_x, res_y = pop_transform.a, -pop_transform.e\n",
    "    x_coords = np.arange(0.5, width) * res_x + pop_transform.c\n",
    "    y_coords = pop_transform.f - np.arange(0.5, height) * res_y\n",
    "    xx, yy = np.meshgrid(x_coords, y_coords)\n",
    "\n",
    "    # Flatten arrays\n",
    "    pop_vals = pop_data[valid_mask]\n",
    "    exp_vals = np.where(exposed_mask, pop_data, 0)[valid_mask]\n",
    "    x = xx[valid_mask]\n",
    "    y = yy[valid_mask]\n",
    "\n",
    "    # Build GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame({\n",
    "        'pop': pop_vals,\n",
    "        'exposed_pop': exp_vals\n",
    "    }, geometry=gpd.points_from_xy(x, y), crs=\"EPSG:4326\")\n",
    "\n",
    "    # Spatial join with ADM2 zones\n",
    "    joined = gpd.sjoin(gdf, adm2[['globalid', 'L0_CODE', 'L0_NAME', 'L1_CODE', 'L1_NAME', 'L2_CODE', 'L2_NAME', 'wb_status', 'sovereign', 'Disputed', 'geometry']], how='inner', predicate='intersects')\n",
    "\n",
    "    # --- Aggregate by ADM2 unit ---\n",
    "    grouped = joined.groupby('globalid').agg({\n",
    "        'pop': 'sum',\n",
    "        'exposed_pop': 'sum'\n",
    "    }).reset_index().rename(columns={\n",
    "        'pop': 'total_pop',\n",
    "        'exposed_pop': 'exposed_pop'\n",
    "    })\n",
    "    grouped['percent_exposed'] = 100 * grouped['exposed_pop'] / grouped['total_pop']\n",
    "    grouped['year'] = year\n",
    "    grouped['geo_level'] = 2\n",
    "\n",
    "    # Merge with ADM2 shapefile and save full dataset\n",
    "    merged_df = adm2.merge(grouped, on='globalid', how='left').drop(columns='geometry', errors='ignore')\n",
    "    output_csv_full = os.path.join(output_dir, f\"pm25_exposure_by_admin2_full_{year}.csv\")\n",
    "    merged_df.to_csv(output_csv_full, index=False)\n",
    "    print(f\"✅ Full dataset saved to {output_csv_full}\")\n",
    "\n",
    "    # --- Aggregated by L2_CODE ---\n",
    "    agg_df = merged_df.groupby('L2_CODE').agg({\n",
    "        'L0_CODE': 'first',\n",
    "        'L0_NAME': 'first',\n",
    "        'L1_CODE': 'first',\n",
    "        'L1_NAME': 'first',\n",
    "        'L2_NAME': 'first',\n",
    "        'total_pop': 'sum',\n",
    "        'exposed_pop': 'sum',\n",
    "        'percent_exposed': 'mean',\n",
    "        'geo_level': 'first',\n",
    "        'wb_status': 'first',\n",
    "        'sovereign': 'first',\n",
    "        'Disputed': 'first',\n",
    "        'year': 'first'\n",
    "    }).reset_index()\n",
    "\n",
    "    output_csv_agg = os.path.join(output_dir, f\"pm25_exposure_by_admin2_aggregated_{year}.csv\")\n",
    "    agg_df.to_csv(output_csv_agg, index=False)\n",
    "    print(f\"✅ Aggregated dataset saved to {output_csv_agg}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05c92c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env39-mkt)",
   "language": "python",
   "name": "env39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
