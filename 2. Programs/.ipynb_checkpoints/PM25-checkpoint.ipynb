{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5222c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔️ Already exists: afg_ppp_2010_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2010_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2010_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2010_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2010_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2010_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2010_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2010_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: afg_ppp_2011_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2011_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2011_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2011_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2011_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2011_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2011_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2011_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: afg_ppp_2012_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2012_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2012_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2012_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2012_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2012_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2012_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2012_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: afg_ppp_2013_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2013_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2013_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2013_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2013_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2013_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2013_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2013_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: afg_ppp_2014_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2014_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2014_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2014_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2014_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2014_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2014_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2014_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: afg_ppp_2015_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2015_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2015_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2015_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2015_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2015_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2015_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2015_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: afg_ppp_2016_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2016_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2016_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2016_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2016_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2016_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2016_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2016_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: afg_ppp_2017_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2017_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2017_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2017_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2017_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2017_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2017_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2017_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: afg_ppp_2018_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2018_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2018_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2018_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2018_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2018_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2018_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2018_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: afg_ppp_2019_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2019_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2019_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2019_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2019_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2019_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2019_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2019_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: afg_ppp_2020_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2020_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2020_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2020_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2020_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2020_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2020_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2020_1km_Aggregated_UNadj.tif\n",
      "✔️ Already exists: afg_ppp_2021_1km_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2021_1km_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2021_1km_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2021_1km_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2021_1km_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2021_1km_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2021_1km_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2021_1km_UNadj.tif\n",
      "✔️ Already exists: afg_ppp_2022_1km_UNadj.tif\n",
      "✔️ Already exists: bgd_ppp_2022_1km_UNadj.tif\n",
      "✔️ Already exists: btn_ppp_2022_1km_UNadj.tif\n",
      "✔️ Already exists: ind_ppp_2022_1km_UNadj.tif\n",
      "✔️ Already exists: mdv_ppp_2022_1km_UNadj.tif\n",
      "✔️ Already exists: npl_ppp_2022_1km_UNadj.tif\n",
      "✔️ Already exists: pak_ppp_2022_1km_UNadj.tif\n",
      "✔️ Already exists: lka_ppp_2022_1km_UNadj.tif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# Output directory\n",
    "output_dir = r\"C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# South Asia ISO3 codes\n",
    "south_asia_iso3 = {\n",
    "    'AFG': 'Afghanistan',\n",
    "    'BGD': 'Bangladesh',\n",
    "    'BTN': 'Bhutan',\n",
    "    'IND': 'India',\n",
    "    'MDV': 'Maldives',\n",
    "    'NPL': 'Nepal',\n",
    "    'PAK': 'Pakistan',\n",
    "    'LKA': 'Sri_Lanka'\n",
    "}\n",
    "\n",
    "# URL base by year and structure\n",
    "def build_url(year, iso3):\n",
    "    iso3_lower = iso3.lower()\n",
    "    \n",
    "    if year <= 2020:\n",
    "        base_url = f\"https://data.worldpop.org/GIS/Population/Global_2000_2020_1km_UNadj/{year}/{iso3}/\"\n",
    "        filename = f\"{iso3_lower}_ppp_{year}_1km_Aggregated_UNadj.tif\"\n",
    "    else:\n",
    "        base_url = f\"https://data.worldpop.org/GIS/Population/Global_2021_2022_1km_UNadj/unconstrained/{year}/{iso3}/\"\n",
    "        filename = f\"{iso3_lower}_ppp_{year}_1km_UNadj.tif\"\n",
    "    \n",
    "    return base_url + filename, filename\n",
    "\n",
    "# Download loop\n",
    "for year in range(2010, 2023):\n",
    "    for iso3 in south_asia_iso3:\n",
    "        url, filename = build_url(year, iso3)\n",
    "        save_path = os.path.join(output_dir, f\"{iso3}_{year}.tif\")\n",
    "\n",
    "        if os.path.exists(save_path):\n",
    "            print(f\"✔️ Already exists: {filename}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"⬇️ Downloading {filename} from {url}...\")\n",
    "        r = requests.get(url, stream=True)\n",
    "        if r.status_code == 200:\n",
    "            with open(save_path, 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "            print(f\"✅ Saved to: {save_path}\")\n",
    "        else:\n",
    "            print(f\"❌ Failed to download {filename} (Status code: {r.status_code})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8305a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Data for  PM25 cannot be downaloaed with script ; it is hosted in BOX \n",
    "#  https://sites.wustl.edu/acag/datasets/surface-pm2-5/#V5.GL.05.02\n",
    "#  https://wustl.app.box.com/v/ACAG-V5GL0502-GWRPM25/folder/293382100161\n",
    "#  Manual Download "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d705b28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables in file: ['lon', 'lat', 'GWRPM25']\n"
     ]
    }
   ],
   "source": [
    "from netCDF4 import Dataset\n",
    "\n",
    "# Path to your NetCDF file\n",
    "nc_path = r\"C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\V5GL0502.HybridPM25.Asia.201001-201012.nc\"\n",
    "\n",
    "# Open file\n",
    "ds = Dataset(nc_path, mode='r')\n",
    "\n",
    "# List all variables\n",
    "print(\"Variables in file:\", list(ds.variables.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2c379a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Processing year 2010...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vgald\\AppData\\Local\\Temp\\ipykernel_13028\\1951518950.py:86: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  intersect['intersection_area'] = intersect.geometry.area\n",
      "C:\\Users\\vgald\\AppData\\Local\\Temp\\ipykernel_13028\\1951518950.py:92: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  intersect_zone['zone_area'] = intersect_zone.geometry.area\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Full dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin0_full_2010.csv\n",
      "✅ Aggregated dataset saved to C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\\pm25_exposure_by_admin0_aggregated_2010.csv\n",
      "\n",
      "🔄 Processing year 2011...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vgald\\AppData\\Local\\Temp\\ipykernel_13028\\1951518950.py:86: UserWarning: Geometry is in a geographic CRS. Results from 'area' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  intersect['intersection_area'] = intersect.geometry.area\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import box\n",
    "from netCDF4 import Dataset\n",
    "from rasterio.transform import from_bounds\n",
    "\n",
    "# Paths\n",
    "pop_dir = r\"C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\"\n",
    "pm25_dir = r\"C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\"\n",
    "shapefile_path = r\"C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Shapefile\\WB_GAD\\WB_GAD_ADM0_SAR_Clean.shp\"\n",
    "output_dir = r\"C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\3. Output\\PM25\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load shapefile\n",
    "shp_df = gpd.read_file(shapefile_path).to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Years to process\n",
    "years = [str(y) for y in range(2010, 2023)]\n",
    "\n",
    "# Helper: Raster to polygons using from_bounds transform\n",
    "def raster_to_polygons_manual(data, transform):\n",
    "    polygons, values, areas = [], [], []\n",
    "    height, width = data.shape\n",
    "    res_x = transform.a\n",
    "    res_y = -transform.e  # pixel height (positive)\n",
    "\n",
    "    for row in range(height):\n",
    "        for col in range(width):\n",
    "            val = data[row, col]\n",
    "            if not np.isnan(val) and val >= 0:\n",
    "                x = transform.c + col * res_x\n",
    "                y = transform.f - row * res_y\n",
    "                poly = box(x, y - res_y, x + res_x, y)\n",
    "                polygons.append(poly)\n",
    "                values.append(val)\n",
    "                areas.append(poly.area)\n",
    "\n",
    "    return gpd.GeoDataFrame({'value': values, 'cell_area': areas, 'geometry': polygons}, crs=\"EPSG:4326\")\n",
    "\n",
    "# Loop through years\n",
    "for year in years:\n",
    "    print(f\"\\n🔄 Processing year {year}...\")\n",
    "\n",
    "    # --- Step 1: Load PM2.5 from NetCDF ---\n",
    "    pm25_path = os.path.join(pm25_dir, f\"V5GL0502.HybridPM25.Asia.{year}01-{year}12.nc\")\n",
    "    ds = Dataset(pm25_path)\n",
    "    pm25_data = ds.variables['GWRPM25'][ :, :]\n",
    "    lats = ds.variables['lat'][:]\n",
    "    lons = ds.variables['lon'][:]\n",
    "    ds.close()\n",
    "\n",
    "    # Flip data if lat is descending\n",
    "    if lats[0] > lats[-1]:\n",
    "        pm25_data = pm25_data[::-1, :]\n",
    "        lats = lats[::-1]\n",
    "\n",
    "    # Define transform from bounds\n",
    "    height, width = pm25_data.shape\n",
    "    transform = from_bounds(lons.min(), lats.min(), lons.max(), lats.max(), width, height)\n",
    "\n",
    "    # Raster to polygons\n",
    "    gdf_pm25 = raster_to_polygons_manual(pm25_data, transform)\n",
    "    gdf_pm25['above_who'] = gdf_pm25['value'] > 5\n",
    "\n",
    "    # --- Step 2: Load and combine population for South Asia ---\n",
    "    gdf_list = []\n",
    "    for iso3 in ['AFG', 'BGD', 'BTN', 'IND', 'MDV', 'NPL', 'PAK', 'LKA']:\n",
    "        pop_path = os.path.join(pop_dir, f\"{iso3}_{year}.tif\")\n",
    "        if os.path.exists(pop_path):\n",
    "            with rasterio.open(pop_path) as pop_src:\n",
    "                pop_data = pop_src.read(1, masked=True)\n",
    "                pop_transform = pop_src.transform\n",
    "                gdf = raster_to_polygons_manual(pop_data, pop_transform)\n",
    "                gdf = gdf[gdf['value'] > 0]\n",
    "                gdf_list.append(gdf)\n",
    "\n",
    "    gdf_pop = pd.concat(gdf_list, ignore_index=True).set_crs(\"EPSG:4326\")\n",
    "\n",
    "    # --- Step 3: Intersect population and PM2.5 ---\n",
    "    gdf_pop = gdf_pop.rename(columns={'cell_area': 'pop_cell_area'})\n",
    "    intersect = gpd.overlay(gdf_pop, gdf_pm25[['geometry', 'above_who', 'cell_area']], how='intersection')\n",
    "    \n",
    "    intersect['intersection_area'] = intersect.geometry.area\n",
    "    intersect['pop_weighted'] = intersect['value'] * (intersect['intersection_area'] / intersect['pop_cell_area'])\n",
    "    intersect['exposed'] = intersect['pop_weighted'].where(intersect['above_who'], 0)\n",
    "\n",
    "    # --- Step 4: Intersect with ADM0 shapefile ---\n",
    "    intersect_zone = gpd.overlay(intersect, shp_df, how='intersection')\n",
    "    intersect_zone['zone_area'] = intersect_zone.geometry.area\n",
    "    intersect_zone['pop_final'] = intersect_zone['pop_weighted'] * (intersect_zone['zone_area'] / intersect_zone['intersection_area'])\n",
    "    intersect_zone['exposed_final'] = intersect_zone['exposed'] * (intersect_zone['zone_area'] / intersect_zone['intersection_area'])\n",
    "\n",
    "    # --- Step 5: Aggregate by globalid ---\n",
    "    grouped = intersect_zone.groupby('globalid').agg({\n",
    "        'pop_final': 'sum',\n",
    "        'exposed_final': 'sum'\n",
    "    }).reset_index().rename(columns={\n",
    "        'pop_final': 'total_pop',\n",
    "        'exposed_final': 'exposed_pop'\n",
    "    })\n",
    "\n",
    "    grouped['percent_exposed'] = 100 * grouped['exposed_pop'] / grouped['total_pop']\n",
    "    grouped['year'] = year\n",
    "    grouped['geo_level'] = 0\n",
    "\n",
    "    # --- Step 6: Merge with shapefile and save full dataset ---\n",
    "    merged_df = shp_df.merge(grouped, on='globalid', how='left')\n",
    "    merged_df = merged_df.drop(columns=['geometry'], errors='ignore')\n",
    "\n",
    "    output_csv_full = os.path.join(output_dir, f\"pm25_exposure_by_admin0_full_{year}.csv\")\n",
    "    merged_df.to_csv(output_csv_full, index=False)\n",
    "    print(f\"✅ Full dataset saved to {output_csv_full}\")\n",
    "\n",
    "    # --- Step 7: Aggregated summary by L0_CODE ---\n",
    "    agg_df = merged_df.groupby(['L0_CODE']).agg({\n",
    "        'L0_NAME': 'first',\n",
    "        'total_pop': 'sum',\n",
    "        'exposed_pop': 'sum',\n",
    "        'percent_exposed': 'mean',\n",
    "        'geo_level': 'first',\n",
    "        'wb_status': 'first',\n",
    "        'sovereign': 'first',\n",
    "        'Disputed': 'first',\n",
    "        'year': 'first'\n",
    "    }).reset_index()\n",
    "\n",
    "    output_csv_agg = os.path.join(output_dir, f\"pm25_exposure_by_admin0_aggregated_{year}.csv\")\n",
    "    agg_df.to_csv(output_csv_agg, index=False)\n",
    "    print(f\"✅ Aggregated dataset saved to {output_csv_agg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "554d1f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Processing year 2010...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2010.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2010.tif\n",
      "\n",
      "🔄 Processing year 2011...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2011.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2011.tif\n",
      "\n",
      "🔄 Processing year 2012...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2012.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2012.tif\n",
      "\n",
      "🔄 Processing year 2013...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2013.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2013.tif\n",
      "\n",
      "🔄 Processing year 2014...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2014.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2014.tif\n",
      "\n",
      "🔄 Processing year 2015...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2015.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2015.tif\n",
      "\n",
      "🔄 Processing year 2016...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2016.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2016.tif\n",
      "\n",
      "🔄 Processing year 2017...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2017.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2017.tif\n",
      "\n",
      "🔄 Processing year 2018...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2018.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2018.tif\n",
      "\n",
      "🔄 Processing year 2019...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2019.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2019.tif\n",
      "\n",
      "🔄 Processing year 2020...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2020.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2020.tif\n",
      "\n",
      "🔄 Processing year 2021...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2021.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2021.tif\n",
      "\n",
      "🔄 Processing year 2022...\n",
      "✅ PM2.5 saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\\tifs\\pm25_2022.tif\n",
      "✅ Population mosaic saved to: C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\\tifs\\pop_south_asia_2022.tif\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from netCDF4 import Dataset\n",
    "from rasterio.transform import from_bounds\n",
    "from rasterio.merge import merge\n",
    "from rasterio.crs import CRS\n",
    "\n",
    "# Years to process\n",
    "years = [str(y) for y in range(2010, 2023)]\n",
    "\n",
    "# PM2.5 paths\n",
    "pm25_nc_dir = r\"C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\PM25\\V5GL0502\"\n",
    "pm25_tif_dir = os.path.join(pm25_nc_dir, \"tifs\")\n",
    "os.makedirs(pm25_tif_dir, exist_ok=True)\n",
    "\n",
    "# Population paths\n",
    "pop_dir = r\"C:\\Users\\vgald\\OneDrive\\Desktop\\SAR_DATA\\1. Data\\Population\\WorldPop_SouthAsia\"\n",
    "pop_tif_dir = os.path.join(pop_dir, \"tifs\")\n",
    "os.makedirs(pop_tif_dir, exist_ok=True)\n",
    "\n",
    "# ISO3 list for South Asia\n",
    "iso3_list = ['AFG', 'BGD', 'BTN', 'IND', 'MDV', 'NPL', 'PAK', 'LKA']\n",
    "\n",
    "# Processing loop\n",
    "for year in years:\n",
    "    print(f\"\\n🔄 Processing year {year}...\")\n",
    "\n",
    "    # === PM2.5 NetCDF to TIFF ===\n",
    "    nc_file = os.path.join(pm25_nc_dir, f\"V5GL0502.HybridPM25.Asia.{year}01-{year}12.nc\")\n",
    "    ds = Dataset(nc_file)\n",
    "    pm25_data = ds.variables['GWRPM25'][:, :]\n",
    "    lats = ds.variables['lat'][:]\n",
    "    lons = ds.variables['lon'][:]\n",
    "    ds.close()\n",
    "\n",
    "    # Flip if lat is descending\n",
    "    if lats[0] > lats[-1]:\n",
    "        lats = lats[::-1]\n",
    "\n",
    "    height, width = pm25_data.shape\n",
    "    if lats[0] > lats[-1]:\n",
    "        transform = from_bounds(lons.min(), lats.max(), lons.max(), lats.min(), width, height)\n",
    "    else:\n",
    "        transform = from_bounds(lons.min(), lats.min(), lons.max(), lats.max(), width, height)\n",
    "    pm25_output_path = os.path.join(pm25_tif_dir, f\"pm25_{year}.tif\")\n",
    "    with rasterio.open(\n",
    "        pm25_output_path,\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=height,\n",
    "        width=width,\n",
    "        count=1,\n",
    "        dtype=pm25_data.dtype,\n",
    "        crs=CRS.from_epsg(4326),\n",
    "        transform=transform,\n",
    "        nodata=-999\n",
    "    ) as dst:\n",
    "        dst.write(pm25_data, 1)\n",
    "\n",
    "    print(f\"✅ PM2.5 saved to: {pm25_output_path}\")\n",
    "\n",
    "    # === Population Mosaic to TIFF ===\n",
    "    src_files = []\n",
    "    for iso3 in iso3_list:\n",
    "        pop_file = os.path.join(pop_dir, f\"{iso3}_{year}.tif\")\n",
    "        if os.path.exists(pop_file):\n",
    "            src = rasterio.open(pop_file)\n",
    "            src_files.append(src)\n",
    "        else:\n",
    "            print(f\"⚠️ Missing: {pop_file}\")\n",
    "\n",
    "    if src_files:\n",
    "        mosaic, out_transform = merge(src_files, nodata=0)\n",
    "        out_meta = src_files[0].meta.copy()\n",
    "        out_meta.update({\n",
    "            \"driver\": \"GTiff\",\n",
    "            \"height\": mosaic.shape[1],\n",
    "            \"width\": mosaic.shape[2],\n",
    "            \"transform\": out_transform,\n",
    "            \"nodata\": 0,\n",
    "            \"crs\": CRS.from_epsg(4326)\n",
    "        })\n",
    "\n",
    "        pop_output_path = os.path.join(pop_tif_dir, f\"pop_south_asia_{year}.tif\")\n",
    "        with rasterio.open(pop_output_path, \"w\", **out_meta) as dest:\n",
    "            dest.write(mosaic)\n",
    "\n",
    "        print(f\"✅ Population mosaic saved to: {pop_output_path}\")\n",
    "\n",
    "        for src in src_files:\n",
    "            src.close()\n",
    "    else:\n",
    "        print(f\"❌ No population data found for {year}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88696d13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env39-mkt)",
   "language": "python",
   "name": "env39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
